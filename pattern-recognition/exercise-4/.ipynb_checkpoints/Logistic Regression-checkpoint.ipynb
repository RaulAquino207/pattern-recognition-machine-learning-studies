{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Student: Gabriel Jonas da Silva Duarte</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice of Machine Learning - IFCE - 2020.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-78584ae46b41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading and filtering the dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Filtering the dataset for training\n",
    "train_dataset = datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "idx = (train_dataset.targets==1) | (train_dataset.targets==3)\n",
    "train_dataset.targets = train_dataset.targets[idx]\n",
    "train_dataset.data = train_dataset.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2145, 28, 28])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and Filtering the dataset for test\n",
    "test_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\n",
    "indx = (test_dataset.targets==1) | (test_dataset.targets==3)\n",
    "test_dataset.targets = test_dataset.targets[indx]\n",
    "test_dataset.data = test_dataset.data[indx]\n",
    "test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Treating data set and define new labels for the selected numbers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: torch.Size([2145, 784])\n",
      "Img class: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_training_samples = train_dataset.data.shape[0]\n",
    "learning_rate = 1e-4 #Setting the learning rate\n",
    "\n",
    "\n",
    "train_data = train_dataset.data.view(n_training_samples, -1) #Arranging in 28x28 vectors\n",
    "train_targets = train_dataset.targets.view(n_training_samples, -1)\n",
    "y_train = train_targets.float()\n",
    "x_train = train_data.float()\n",
    "\n",
    "\n",
    "\n",
    "y_train[y_train==1] = -1\n",
    "y_train[y_train==3] = 1\n",
    "\n",
    "\n",
    "\n",
    "n_test_samples = test_dataset.data.shape[0]\n",
    "test_data = test_dataset.data.view(n_test_samples, -1)\n",
    "test_targets = test_dataset.targets.view(n_test_samples, -1)\n",
    "\n",
    "y_test = test_targets.float()\n",
    "x_test = test_data.float()\n",
    "\n",
    "y_test[y_test==1] = -1\n",
    "y_test[y_test==3] = 1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Test data:', x_test.shape)\n",
    "print('Img class:', y_test[3].item())\n",
    "img = test_data[3].view(28, 28)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h(\\vec x) = logistic(\\vec x^T \\vec \\theta)\\\\\n",
    "            = \\frac{1}{1+e^{\\vec -x^T \\vec \\theta}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou seja $$P(y= +1/ \\vec x) = h(\\vec x) \\\\\n",
    "           p(y = -1 / \\vec x) = 1-h(\\vec x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>O treinamento se dará através do maximum likelihood(Principio da máxima verossimilhança)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\vec \\theta}_{ML} = argmax \\prod_{n=1}^{N} P_{\\vec \\theta}(Y_n / \\vec X_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$= argmax \\sum_{n=1}^{N} log\\ P_{\\vec \\theta}(Y_n/\\vec X_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{\\vec \\theta} = \\left \\{ \\begin{matrix} logistic(\\vec x^T\\theta) & \\mbox{, }\\mbox{ y=1} \\\\ 1-logistic(\\vec x^T\\theta) & \\mbox{, }\\mbox{ y=-1} \\end{matrix} \\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podendo ser Reescrito como equação unica.$$\\\\\\boxed{P_{\\vec \\theta} = logistic(y\\vec x^T\\theta)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,n_epochs,learning_rate):\n",
    "    theta = torch.zeros(784,1)\n",
    "    for epoch in range(n_epochs):\n",
    "        denominator = 1 + torch.exp(y*(x @ theta))\n",
    "        numerator = y * x\n",
    "        gradient = -torch.mean(numerator/denominator,axis=0, keepdim=True).T\n",
    "        theta = theta - learning_rate* gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = train(x_train,y_train,100,learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aproach: 99.44055944055944\n"
     ]
    }
   ],
   "source": [
    "#y_hat = 1/(1+torch.exp(-x_test@theta))\n",
    "y_hat = torch.sigmoid(x_test@theta)\n",
    "\n",
    "y_hat[y_hat < 0.5] = -1\n",
    "y_hat[y_hat >= 0.5] = 1\n",
    "\n",
    "correto = 0\n",
    "\n",
    "for i in range(y_hat.shape[0]):\n",
    "    if(y_hat[i] == y_test[i]):\n",
    "        correto += 1\n",
    "accuracy = 100 * correto/y_hat.shape[0]\n",
    "accuracy\n",
    "print(\"Aproach:\", accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os pares a acurácia foi de aproximadamente: <br>\n",
    "(5,7) = 99,2% <br>\n",
    "(2,7) = 98%   <br>\n",
    "(1,2) = 99.2% <br>\n",
    "(1,3) = 99,4% <br>\n",
    "\n",
    "a melhor acurácia foi para os pares de digitos (1,3) e a pior foi para os pares(2,7)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
